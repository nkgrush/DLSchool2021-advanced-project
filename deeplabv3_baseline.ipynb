{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeplabv3_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o73wEzbglNDl"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAASAcQHA6oq"
      },
      "source": [
        "%matplotlib inline\n",
        " \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/MayaChallenge/\n",
        " \n",
        "!easy_install GDAL\n",
        " \n",
        "# !unzip ./DiscoverMayaChallenge_data.zip -d ./data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0OjtvjKPROc"
      },
      "source": [
        "from segmentation_transforms import Compose, RandomHorizontalFlip, RandomCrop, Normalize, RandomResize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-jKUvpc8wCB"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os\n",
        " \n",
        "from osgeo import gdal, gdal_array\n",
        " \n",
        "from pathlib import Path\n",
        "from copy import copy\n",
        "from torch.utils.data import Dataset, random_split\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms as T\n",
        "from torch.nn import functional as F\n",
        "from segmentation_transforms import Compose, RandomHorizontalFlip, RandomCrop, Normalize, RandomResize\n",
        "import torchvision.transforms.functional as transforms_F\n",
        " \n",
        "import pickle\n",
        " \n",
        "from pathlib import Path\n",
        " \n",
        "from chactun_dataset import ChactunDataset, UpsampleSentinelToLidar\n",
        " \n",
        "mask_train_path = Path('./data/train_masks')\n",
        "lidar_train_path = Path('./data/lidar_train')\n",
        "sent1_train_path = Path('./data/Sentinel1_train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJeKRIeo676N"
      },
      "source": [
        "## Общий config эксперимента"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qtb5pBsr669E"
      },
      "source": [
        "class DotDict(dict):\n",
        "    def __getattr__(self, attr):\n",
        "        return self.get(attr)\n",
        "\n",
        "    def __setattr__(self, key, value):\n",
        "        self.__setitem__(key, value)\n",
        "\n",
        "config = DotDict()\n",
        "config.resize_min = 250\n",
        "config.resize_max = 250\n",
        "config.crop_size = 250\n",
        "config.pretrained = True\n",
        "config.num_classes = len(ChactunDataset.classes)\n",
        "config.batch_size = 4\n",
        "config.epochs = 40\n",
        "config.lr = 1e-3\n",
        "config.momentum = 0.9\n",
        "config.sentinel1_bands = []\n",
        "config.sentinel2_bands = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC8dAnrU7wvC"
      },
      "source": [
        "!ls data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rrhSp2WSBVm"
      },
      "source": [
        "def get_transofrms(h_flip_prob, resize_min, resize_max, crop_size, mean, std):\n",
        "    train_transform = Compose([        \n",
        "        UpsampleSentinelToLidar(),\n",
        "        RandomResize(resize_min, resize_max),\n",
        "        RandomCrop(crop_size)\n",
        "    ])\n",
        "    test_transform = Compose([\n",
        "        UpsampleSentinelToLidar()\n",
        "    ])\n",
        "\n",
        "    return train_transform, test_transform\n",
        "\n",
        "def get_dataset(config, root='./data', val_size=0.25):\n",
        "    train_transform, test_transform = get_transofrms(\n",
        "        config.h_flip_prob,\n",
        "        config.resize_min,\n",
        "        config.resize_max,\n",
        "        config.crop_size,\n",
        "        config.mean,\n",
        "        config.std\n",
        "    )\n",
        "\n",
        "    ds = ChactunDataset(root, is_train=True, transform=train_transform,\n",
        "                        sentinel1_bands=config.sentinel1_bands,\n",
        "                        sentinel2_bands=config.sentinel2_bands)\n",
        "    train_ds, val_ds = random_split(ds, [len(ds) - int(len(ds) * val_size), \n",
        "                                        int(len(ds) * val_size)])\n",
        "\n",
        "    test_ds = ChactunDataset(root, is_train=False, transform=test_transform,\n",
        "                             sentinel1_bands=config.sentinel1_bands,\n",
        "                             sentinel2_bands=config.sentinel2_bands)\n",
        "\n",
        "    return train_ds, val_ds, test_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PyeivCidTsS"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        " \n",
        "train_ds, val_ds, test_ds = get_dataset(config, './data')\n",
        " \n",
        "train_dl = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True, drop_last=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=config.batch_size, shuffle=True, drop_last=True)\n",
        "test_dl = DataLoader(test_ds, batch_size=config.batch_size, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVKRyRMgQEjE"
      },
      "source": [
        "train_ds[0][0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCi2PShR_yO2"
      },
      "source": [
        "# Модель.\n",
        "\n",
        "В качестве baseline выбранна архитектура DeepLabv3 с предобученными весами, которая будет дообучена на 3-х канальных изображениях с лидара.\n",
        "\n",
        "- Для выходов модели используется сигмоида.\n",
        "- Функция потерь - бинарная кросс-энтропия.\n",
        "- Оптимизатор SGD.\n",
        "- Learning rate снижается с помощью OneCycleLR.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rWNIXJAPY61"
      },
      "source": [
        "from torchvision import models\n",
        " \n",
        "class DeepLabV3(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.model = models.segmentation.deeplabv3_resnet101(\n",
        "            pretrained=self.config.pretrained, progress=True\n",
        "        )\n",
        " \n",
        "        self.model.classifier[4] = nn.Conv2d(256, self.config.num_classes, 1)\n",
        " \n",
        "    def forward(self, X):\n",
        "        return torch.sigmoid(self.model(X)['out'])\n",
        " \n",
        "model = DeepLabV3(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbBtoejBxGFC"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# Стандартное определение лосса, оптимизатора и lr scheduler.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "crit = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=config.momentum)\n",
        "sched = optim.lr_scheduler.OneCycleLR(optimizer, config.lr, \n",
        "                                      epochs=config.epochs, \n",
        "                                      steps_per_epoch=len(train_dl))\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFEFcKTznMST"
      },
      "source": [
        "### Инференс"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvw7P8rygIuX"
      },
      "source": [
        "def discretize_segmentation_maps(probs, thresh):\n",
        "    if thresh is None:\n",
        "        thresh = [0.5, 0.5, 0.5]\n",
        "    if isinstance(thresh, int):\n",
        "        thresh = [thresh] * 3\n",
        "    thresh = torch.from_numpy(np.array(thresh)).to(probs.device)\n",
        "    return probs > thresh[:, None, None]\n",
        "\n",
        "def get_ious(y_pred, y_true, thresh=None, eps=1e-7):\n",
        "    y_pred = discretize_segmentation_maps(y_pred, thresh).float()\n",
        "    y_true = y_true.float()\n",
        "    with torch.no_grad():\n",
        "        intersection = torch.sum(y_true * y_pred, dim=[2, 3])\n",
        "        union = torch.sum(y_true, dim=[2, 3]) + torch.sum(y_pred, dim=[2, 3]) - intersection\n",
        "        ious = ((intersection + + eps) / (union + eps)).mean(dim=0)\n",
        "    return ious"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKiCIXS-nFXr"
      },
      "source": [
        "### W&B используется для построения графиков"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sIax2sjzCyL"
      },
      "source": [
        "!pip install wandb\n",
        " \n",
        "import wandb\n",
        "wandb.init(config=config)\n",
        "wandb.watch(model, log_freq=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Pp_SoYwnly9"
      },
      "source": [
        "### Цикл обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPrU0P8wCC66"
      },
      "source": [
        "from tqdm.notebook import tqdm, trange\n",
        "\n",
        "for i in trange(config.epochs):\n",
        "    model.train()\n",
        "    for X, y in tqdm(train_dl):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(X)\n",
        "        loss = crit(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        sched.step()\n",
        "        \n",
        "        #LOG metrics to wandb\n",
        "        ious = get_ious(pred, y, config.prediction_thresh).cpu()\n",
        "        metrics = {'iou_' + class_name: iou_score.item()\n",
        "                for class_name, iou_score in zip(ChactunDataset.classes, ious)}\n",
        "        metrics['avg_iou'] = ious.mean()\n",
        "        metrics['loss'] = loss.item()\n",
        "        metrics['lr'] = sched.get_last_lr()\n",
        "        wandb.log(metrics)\n",
        "\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    ious = []\n",
        "    for X, y in val_dl:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = model(X)\n",
        "            losses.append(crit(pred, y).item())\n",
        "            iou = get_ious(pred, y, config.prediction_thresh)\n",
        "            ious.append(iou.cpu().numpy())\n",
        "    metrics = {'val_iou_' + class_name: iou_score.item()\n",
        "                for class_name, iou_score in zip(ChactunDataset.classes, np.stack(ious).mean(axis=0))}\n",
        "    metrics['val_avg_iou'] = np.array(ious).mean(axis=0).mean()\n",
        "    metrics['val_loss'] = np.mean(losses)\n",
        "    wandb.log(metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd1SjKL0exLT"
      },
      "source": [
        "torch.save(model.state_dict(), 'model_weights-9.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYA1Nixi_ThY"
      },
      "source": [
        "wandb.run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}